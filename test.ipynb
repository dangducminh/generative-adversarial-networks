{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "import keras.utils as image\n",
    "from keras.layers import Input, Reshape, Dropout, Dense \n",
    "from keras.layers import Flatten, BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import LeakyReLU, ReLU, PReLU\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(data_dir):\n",
    "    images = list()\n",
    "    for file_name in glob.glob(data_dir + '/*.jpg'):\n",
    "        img = image.load_img(file_name) \n",
    "        img = image.img_to_array(img)\n",
    "        images.append(img)\n",
    "    return np.asarray(images) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    \"\"\"\n",
    "    Builds the generator model\n",
    "    \"\"\"\n",
    "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "    model = Sequential(name='generator')\n",
    "  \n",
    "    model.add(Dense(4 * 4 * 1024, kernel_initializer=init, input_dim=latent_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(Reshape((4, 4, 1024)))\n",
    "\n",
    "    model.add(Conv2DTranspose(512, kernel_size=5, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2DTranspose(256, kernel_size=5, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2DTranspose(128, kernel_size=5, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2DTranspose(3, kernel_size=3, strides=2, padding='same',kernel_initializer=init))\n",
    "    model.add(Activation('tanh'))\n",
    " \n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape=(64,64,3)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Builds the generator model\n",
    "    \"\"\"\n",
    "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "    model = Sequential(name='discriminator')\n",
    "  \n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=image_shape, kernel_initializer=init))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=5, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=5, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, kernel_initializer=init))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
    "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
    "\n",
    "    def generator_loss(self, fake_output):\n",
    "        return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "    def discriminator_loss(self, real_output, fake_output):\n",
    "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as discriminator_tape:\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            real_output = self.discriminator(real_images)\n",
    "            fake_output = self.discriminator(generated_images)\n",
    "            d_loss = self.discriminator_loss(real_output, fake_output)\n",
    "        discriminator_grads = discriminator_tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(discriminator_grads, self.discriminator.trainable_weights))\n",
    "        \n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as generator_tape:\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            fake_output = self.discriminator(generated_images)\n",
    "            g_loss = self.generator_loss(fake_output)\n",
    "        generator_grads = generator_tape.gradient(g_loss, self.generator.trainable_weights)     \n",
    "        self.g_optimizer.apply_gradients(zip(generator_grads, self.generator.trainable_weights))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            'd_loss': self.d_loss_metric.result(),\n",
    "            'g_loss': self.g_loss_metric.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0:\n",
    "            random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "            generated_images = self.model.generator(random_latent_vectors)\n",
    "            fig = plt.figure(figsize=(10, 4))\n",
    "            for i in range(self.num_img):\n",
    "                plt.subplot(2, 5, i + 1)\n",
    "                plt.imshow(generated_images[i,:,:,:] * 0.5 + 0.5)\n",
    "                plt.axis('off')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 16384)             2113536   \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 16384)            65536     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_28 (ReLU)             (None, 16384)             0         \n",
      "                                                                 \n",
      " reshape_7 (Reshape)         (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_28 (Conv2D  (None, 8, 8, 512)        13107712  \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 8, 8, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_29 (ReLU)             (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_29 (Conv2D  (None, 16, 16, 256)      3277056   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 16, 16, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_30 (ReLU)             (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_30 (Conv2D  (None, 32, 32, 128)      819328    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 32, 32, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_31 (ReLU)             (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_31 (Conv2D  (None, 64, 64, 3)        3459      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,390,211\n",
      "Trainable params: 19,355,651\n",
      "Non-trainable params: 34,560\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " leaky_re_lu_28 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 8, 8, 256)         819456    \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_30 (LeakyReLU)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 4, 4, 512)         3277312   \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_31 (LeakyReLU)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 8193      \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,184,193\n",
      "Trainable params: 4,182,401\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = DCGAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    g_optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = read_images('./cat/')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = gan.fit(X_train, epochs=50, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
